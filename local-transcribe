#!/usr/bin/env python

from faster_whisper import WhisperModel
import os
import multiprocessing

# Use 'cpu' and 'int8' for maximum speed on your processor
model = WhisperModel("large-v3-turbo", device="cpu", compute_type="int8", cpu_threads=multiprocessing.cpu_count())

def transcribe(file_path):
    # This will process roughly 5-10x faster than real-time on a modern CPU
    segments, info = model.transcribe(file_path, beam_size=1) # beam_size=1 is fastest
    
    # Build output path in whisper/ with same structure as audio/
    rel_path = os.path.relpath(file_path, "audio")
    out_dir = os.path.join("whisper", os.path.dirname(rel_path))
    os.makedirs(out_dir, exist_ok=True)
    output_file = os.path.join(out_dir, f"{os.path.splitext(os.path.basename(file_path))[0]}.txt")
    # Skip if already transcribed
    if os.path.exists(output_file):
        print(f"⏩ Skipping (already transcribed): {output_file}")
        return
    with open(output_file, "w") as f:
        for segment in segments:
            f.write(f"[{segment.start:.2f}s] {segment.text}\n")
    print(f"✅ Finished: {output_file}")

# Walk through your audio folder
for root, _, files in os.walk("./audio"):
    for file in files:
        if file.endswith(".m4a"):
            transcribe(os.path.join(root, file))